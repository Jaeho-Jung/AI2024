{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datasets = pickle.load(f)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X_train shape = (10, 850), y_train shape = (850,)\n",
      "Development set: X_dev shape = (10, 50), y_dev shape = (50,)\n",
      "Test set: X_test shape = (10, 100), y_test shape = (100,)\n",
      "Iteration 1/100: Training Loss = 2245.9618535604964\n",
      "Validation Loss = 2245.9618535604964\n",
      "Iteration 2/100: Training Loss = 776.1036501627084\n",
      "Validation Loss = 776.1036501627084\n",
      "Iteration 3/100: Training Loss = 274.9157442532406\n",
      "Validation Loss = 274.9157442532406\n",
      "Iteration 4/100: Training Loss = 98.88831208337116\n",
      "Validation Loss = 98.88831208337116\n",
      "Iteration 5/100: Training Loss = 35.520467441660685\n",
      "Validation Loss = 35.520467441660685\n",
      "Iteration 6/100: Training Loss = 13.376467409950367\n",
      "Validation Loss = 13.376467409950367\n",
      "Iteration 7/100: Training Loss = 5.4083714169607955\n",
      "Validation Loss = 5.4083714169607955\n",
      "Iteration 8/100: Training Loss = 2.599498869654456\n",
      "Validation Loss = 2.599498869654456\n",
      "Iteration 9/100: Training Loss = 1.539702587584912\n",
      "Validation Loss = 1.539702587584912\n",
      "Iteration 10/100: Training Loss = 1.1563429472937785\n",
      "Validation Loss = 1.1563429472937785\n",
      "Iteration 11/100: Training Loss = 1.0162176635295352\n",
      "Validation Loss = 1.0162176635295352\n",
      "Iteration 12/100: Training Loss = 0.9620559746161046\n",
      "Validation Loss = 0.9620559746161046\n",
      "Iteration 13/100: Training Loss = 0.9425308495117244\n",
      "Validation Loss = 0.9425308495117244\n",
      "Iteration 14/100: Training Loss = 0.93646105938496\n",
      "Validation Loss = 0.93646105938496\n",
      "Iteration 15/100: Training Loss = 0.9330801404396595\n",
      "Validation Loss = 0.9330801404396595\n",
      "Iteration 16/100: Training Loss = 0.9310544796861814\n",
      "Validation Loss = 0.9310544796861814\n",
      "Iteration 17/100: Training Loss = 0.9307187408566792\n",
      "Validation Loss = 0.9307187408566792\n",
      "Iteration 18/100: Training Loss = 0.9301585378569901\n",
      "Validation Loss = 0.9301585378569901\n",
      "Iteration 19/100: Training Loss = 0.9296832543329734\n",
      "Validation Loss = 0.9296832543329734\n",
      "Iteration 20/100: Training Loss = 0.9291295288714981\n",
      "Validation Loss = 0.9291295288714981\n",
      "Iteration 21/100: Training Loss = 0.9290209208260245\n",
      "Validation Loss = 0.9290209208260245\n",
      "Early stopping at epoch 21\n",
      "Training finished after 21 iterations\n",
      "Mean squared error: 1.11\n",
      "Coefficient of determination: 1.00\n",
      "Training set: X_train shape = (10, 8500), y_train shape = (8500,)\n",
      "Development set: X_dev shape = (10, 500), y_dev shape = (500,)\n",
      "Test set: X_test shape = (10, 1000), y_test shape = (1000,)\n",
      "Iteration 1/100: Training Loss = 1.4482828534694738\n",
      "Validation Loss = 1.4482828534694738\n",
      "Iteration 2/100: Training Loss = 1.0264575765743769\n",
      "Validation Loss = 1.0264575765743769\n",
      "Iteration 3/100: Training Loss = 1.0276290375556794\n",
      "Validation Loss = 1.0276290375556794\n",
      "Iteration 4/100: Training Loss = 1.0205654147487908\n",
      "Validation Loss = 1.0205654147487908\n",
      "Iteration 5/100: Training Loss = 1.018940666353084\n",
      "Validation Loss = 1.018940666353084\n",
      "Iteration 6/100: Training Loss = 1.0189908331588662\n",
      "Validation Loss = 1.0189908331588662\n",
      "Iteration 7/100: Training Loss = 1.0170559821370644\n",
      "Validation Loss = 1.0170559821370644\n",
      "Iteration 8/100: Training Loss = 1.014893670106092\n",
      "Validation Loss = 1.014893670106092\n",
      "Iteration 9/100: Training Loss = 1.0141485077397001\n",
      "Validation Loss = 1.0141485077397001\n",
      "Iteration 10/100: Training Loss = 1.015980979656395\n",
      "Validation Loss = 1.015980979656395\n",
      "Iteration 11/100: Training Loss = 1.0137211924618255\n",
      "Validation Loss = 1.0137211924618255\n",
      "Iteration 12/100: Training Loss = 1.0136300330244197\n",
      "Validation Loss = 1.0136300330244197\n",
      "Iteration 13/100: Training Loss = 1.013571400559637\n",
      "Validation Loss = 1.013571400559637\n",
      "Iteration 14/100: Training Loss = 1.0143107199270411\n",
      "Validation Loss = 1.0143107199270411\n",
      "Iteration 15/100: Training Loss = 1.0149169293904972\n",
      "Validation Loss = 1.0149169293904972\n",
      "Iteration 16/100: Training Loss = 1.013351802228298\n",
      "Validation Loss = 1.013351802228298\n",
      "Iteration 17/100: Training Loss = 1.0140832395593555\n",
      "Validation Loss = 1.0140832395593555\n",
      "Early stopping at epoch 17\n",
      "Training finished after 17 iterations\n",
      "Mean squared error: 1.00\n",
      "Coefficient of determination: 1.00\n",
      "Training set: X_train shape = (10, 85000), y_train shape = (85000,)\n",
      "Development set: X_dev shape = (10, 5000), y_dev shape = (5000,)\n",
      "Test set: X_test shape = (10, 10000), y_test shape = (10000,)\n",
      "Iteration 1/100: Training Loss = 0.9911960480159696\n",
      "Validation Loss = 0.9911960480159696\n",
      "Iteration 2/100: Training Loss = 0.9884390875741446\n",
      "Validation Loss = 0.9884390875741446\n",
      "Iteration 3/100: Training Loss = 0.989035238965807\n",
      "Validation Loss = 0.989035238965807\n",
      "Iteration 4/100: Training Loss = 0.9896272529081637\n",
      "Validation Loss = 0.9896272529081637\n",
      "Iteration 5/100: Training Loss = 0.9876460555641275\n",
      "Validation Loss = 0.9876460555641275\n",
      "Iteration 6/100: Training Loss = 0.98831209677852\n",
      "Validation Loss = 0.98831209677852\n",
      "Iteration 7/100: Training Loss = 0.9874930140230386\n",
      "Validation Loss = 0.9874930140230386\n",
      "Iteration 8/100: Training Loss = 0.9912793842935763\n",
      "Validation Loss = 0.9912793842935763\n",
      "Iteration 9/100: Training Loss = 0.9908938880044366\n",
      "Validation Loss = 0.9908938880044366\n",
      "Iteration 10/100: Training Loss = 0.9893397532685421\n",
      "Validation Loss = 0.9893397532685421\n",
      "Iteration 11/100: Training Loss = 0.9881910589448699\n",
      "Validation Loss = 0.9881910589448699\n",
      "Iteration 12/100: Training Loss = 0.9887277368913858\n",
      "Validation Loss = 0.9887277368913858\n",
      "Early stopping at epoch 12\n",
      "Training finished after 12 iterations\n",
      "Mean squared error: 0.97\n",
      "Coefficient of determination: 1.00\n"
     ]
    }
   ],
   "source": [
    "from linear_regression import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    # Load the datasets\n",
    "    train_set, dev_set, test_set = load_dataset(f'myrandomdataset{i}.pkl')\n",
    "\n",
    "    # Unpack the datasets\n",
    "    X_train, y_train = train_set\n",
    "    X_dev, y_dev = dev_set\n",
    "    X_test, y_test = test_set\n",
    "\n",
    "    print(f\"Training set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}\")\n",
    "    print(f\"Development set: X_dev shape = {X_dev.shape}, y_dev shape = {y_dev.shape}\")\n",
    "    print(f\"Test set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}\")\n",
    "\n",
    "    regr = LinearRegression(alpha=0.001, max_iter=100, early_stopping=True, n_iter_no_change=10, batch_size=100)\n",
    "\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regr.predict(X_test)\n",
    "    # print(y_pred)\n",
    "    \n",
    "    print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. diabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100: Training Loss = 25449.92370342507\n",
      "Validation Loss = 25449.92370342507\n",
      "Iteration 2/100: Training Loss = 22539.462108174353\n",
      "Validation Loss = 22539.462108174353\n",
      "Iteration 3/100: Training Loss = 20068.95459294532\n",
      "Validation Loss = 20068.95459294532\n",
      "Iteration 4/100: Training Loss = 17961.459117692462\n",
      "Validation Loss = 17961.459117692462\n",
      "Iteration 5/100: Training Loss = 16175.05104493762\n",
      "Validation Loss = 16175.05104493762\n",
      "Iteration 6/100: Training Loss = 14632.618595276545\n",
      "Validation Loss = 14632.618595276545\n",
      "Iteration 7/100: Training Loss = 13325.821871215505\n",
      "Validation Loss = 13325.821871215505\n",
      "Iteration 8/100: Training Loss = 12215.548674823147\n",
      "Validation Loss = 12215.548674823147\n",
      "Iteration 9/100: Training Loss = 11264.403630068813\n",
      "Validation Loss = 11264.403630068813\n",
      "Iteration 10/100: Training Loss = 10467.87834457023\n",
      "Validation Loss = 10467.87834457023\n",
      "Iteration 11/100: Training Loss = 9790.559854590147\n",
      "Validation Loss = 9790.559854590147\n",
      "Iteration 12/100: Training Loss = 9209.083006451261\n",
      "Validation Loss = 9209.083006451261\n",
      "Iteration 13/100: Training Loss = 8707.927666423668\n",
      "Validation Loss = 8707.927666423668\n",
      "Iteration 14/100: Training Loss = 8289.995059543167\n",
      "Validation Loss = 8289.995059543167\n",
      "Iteration 15/100: Training Loss = 7931.699001070709\n",
      "Validation Loss = 7931.699001070709\n",
      "Iteration 16/100: Training Loss = 7627.527033235642\n",
      "Validation Loss = 7627.527033235642\n",
      "Iteration 17/100: Training Loss = 7362.9745880863065\n",
      "Validation Loss = 7362.9745880863065\n",
      "Iteration 18/100: Training Loss = 7142.2743333762155\n",
      "Validation Loss = 7142.2743333762155\n",
      "Iteration 19/100: Training Loss = 6948.241660119709\n",
      "Validation Loss = 6948.241660119709\n",
      "Iteration 20/100: Training Loss = 6784.849421117475\n",
      "Validation Loss = 6784.849421117475\n",
      "Iteration 21/100: Training Loss = 6645.849707991855\n",
      "Validation Loss = 6645.849707991855\n",
      "Iteration 22/100: Training Loss = 6528.479691876447\n",
      "Validation Loss = 6528.479691876447\n",
      "Iteration 23/100: Training Loss = 6431.645101006354\n",
      "Validation Loss = 6431.645101006354\n",
      "Iteration 24/100: Training Loss = 6345.346006976748\n",
      "Validation Loss = 6345.346006976748\n",
      "Iteration 25/100: Training Loss = 6268.213300442489\n",
      "Validation Loss = 6268.213300442489\n",
      "Iteration 26/100: Training Loss = 6203.61938866888\n",
      "Validation Loss = 6203.61938866888\n",
      "Iteration 27/100: Training Loss = 6149.072749640709\n",
      "Validation Loss = 6149.072749640709\n",
      "Iteration 28/100: Training Loss = 6102.37755410392\n",
      "Validation Loss = 6102.37755410392\n",
      "Iteration 29/100: Training Loss = 6063.531935868234\n",
      "Validation Loss = 6063.531935868234\n",
      "Iteration 30/100: Training Loss = 6029.475464459303\n",
      "Validation Loss = 6029.475464459303\n",
      "Iteration 31/100: Training Loss = 5999.524290408589\n",
      "Validation Loss = 5999.524290408589\n",
      "Iteration 32/100: Training Loss = 5973.237644689312\n",
      "Validation Loss = 5973.237644689312\n",
      "Iteration 33/100: Training Loss = 5951.428931621317\n",
      "Validation Loss = 5951.428931621317\n",
      "Iteration 34/100: Training Loss = 5931.849357731368\n",
      "Validation Loss = 5931.849357731368\n",
      "Iteration 35/100: Training Loss = 5915.529703570738\n",
      "Validation Loss = 5915.529703570738\n",
      "Iteration 36/100: Training Loss = 5900.2705200007385\n",
      "Validation Loss = 5900.2705200007385\n",
      "Iteration 37/100: Training Loss = 5888.719011062069\n",
      "Validation Loss = 5888.719011062069\n",
      "Iteration 38/100: Training Loss = 5877.093547894057\n",
      "Validation Loss = 5877.093547894057\n",
      "Iteration 39/100: Training Loss = 5867.37784248774\n",
      "Validation Loss = 5867.37784248774\n",
      "Iteration 40/100: Training Loss = 5857.8710601653365\n",
      "Validation Loss = 5857.8710601653365\n",
      "Iteration 41/100: Training Loss = 5849.3178560733795\n",
      "Validation Loss = 5849.3178560733795\n",
      "Iteration 42/100: Training Loss = 5841.733959480643\n",
      "Validation Loss = 5841.733959480643\n",
      "Iteration 43/100: Training Loss = 5834.983847376579\n",
      "Validation Loss = 5834.983847376579\n",
      "Iteration 44/100: Training Loss = 5828.286270507932\n",
      "Validation Loss = 5828.286270507932\n",
      "Iteration 45/100: Training Loss = 5822.076883592223\n",
      "Validation Loss = 5822.076883592223\n",
      "Iteration 46/100: Training Loss = 5816.863478723383\n",
      "Validation Loss = 5816.863478723383\n",
      "Iteration 47/100: Training Loss = 5811.924397182655\n",
      "Validation Loss = 5811.924397182655\n",
      "Iteration 48/100: Training Loss = 5807.665549147813\n",
      "Validation Loss = 5807.665549147813\n",
      "Iteration 49/100: Training Loss = 5803.470986922335\n",
      "Validation Loss = 5803.470986922335\n",
      "Iteration 50/100: Training Loss = 5799.550346439013\n",
      "Validation Loss = 5799.550346439013\n",
      "Iteration 51/100: Training Loss = 5795.352916870422\n",
      "Validation Loss = 5795.352916870422\n",
      "Iteration 52/100: Training Loss = 5791.569530179178\n",
      "Validation Loss = 5791.569530179178\n",
      "Iteration 53/100: Training Loss = 5787.781909849056\n",
      "Validation Loss = 5787.781909849056\n",
      "Iteration 54/100: Training Loss = 5783.720795127151\n",
      "Validation Loss = 5783.720795127151\n",
      "Iteration 55/100: Training Loss = 5780.105421746774\n",
      "Validation Loss = 5780.105421746774\n",
      "Iteration 56/100: Training Loss = 5776.75491610152\n",
      "Validation Loss = 5776.75491610152\n",
      "Iteration 57/100: Training Loss = 5773.409254527785\n",
      "Validation Loss = 5773.409254527785\n",
      "Iteration 58/100: Training Loss = 5770.2257280455915\n",
      "Validation Loss = 5770.2257280455915\n",
      "Iteration 59/100: Training Loss = 5766.746678728234\n",
      "Validation Loss = 5766.746678728234\n",
      "Iteration 60/100: Training Loss = 5763.623842036987\n",
      "Validation Loss = 5763.623842036987\n",
      "Iteration 61/100: Training Loss = 5760.262681501809\n",
      "Validation Loss = 5760.262681501809\n",
      "Iteration 62/100: Training Loss = 5757.1524752891455\n",
      "Validation Loss = 5757.1524752891455\n",
      "Iteration 63/100: Training Loss = 5754.115773917648\n",
      "Validation Loss = 5754.115773917648\n",
      "Iteration 64/100: Training Loss = 5751.082265875955\n",
      "Validation Loss = 5751.082265875955\n",
      "Iteration 65/100: Training Loss = 5748.14553208084\n",
      "Validation Loss = 5748.14553208084\n",
      "Iteration 66/100: Training Loss = 5745.072491548239\n",
      "Validation Loss = 5745.072491548239\n",
      "Iteration 67/100: Training Loss = 5741.981934666486\n",
      "Validation Loss = 5741.981934666486\n",
      "Iteration 68/100: Training Loss = 5738.946763875382\n",
      "Validation Loss = 5738.946763875382\n",
      "Iteration 69/100: Training Loss = 5735.872964844867\n",
      "Validation Loss = 5735.872964844867\n",
      "Iteration 70/100: Training Loss = 5732.8624011575785\n",
      "Validation Loss = 5732.8624011575785\n",
      "Iteration 71/100: Training Loss = 5729.862294912249\n",
      "Validation Loss = 5729.862294912249\n",
      "Iteration 72/100: Training Loss = 5726.8013362613565\n",
      "Validation Loss = 5726.8013362613565\n",
      "Iteration 73/100: Training Loss = 5723.9209379585145\n",
      "Validation Loss = 5723.9209379585145\n",
      "Iteration 74/100: Training Loss = 5720.910940210521\n",
      "Validation Loss = 5720.910940210521\n",
      "Iteration 75/100: Training Loss = 5718.032586983747\n",
      "Validation Loss = 5718.032586983747\n",
      "Iteration 76/100: Training Loss = 5715.094869933609\n",
      "Validation Loss = 5715.094869933609\n",
      "Iteration 77/100: Training Loss = 5712.145210486209\n",
      "Validation Loss = 5712.145210486209\n",
      "Iteration 78/100: Training Loss = 5709.140979596125\n",
      "Validation Loss = 5709.140979596125\n",
      "Iteration 79/100: Training Loss = 5706.192048770726\n",
      "Validation Loss = 5706.192048770726\n",
      "Iteration 80/100: Training Loss = 5703.210610964643\n",
      "Validation Loss = 5703.210610964643\n",
      "Iteration 81/100: Training Loss = 5700.2871665383445\n",
      "Validation Loss = 5700.2871665383445\n",
      "Iteration 82/100: Training Loss = 5697.403545114019\n",
      "Validation Loss = 5697.403545114019\n",
      "Iteration 83/100: Training Loss = 5694.469950571187\n",
      "Validation Loss = 5694.469950571187\n",
      "Iteration 84/100: Training Loss = 5691.548227305336\n",
      "Validation Loss = 5691.548227305336\n",
      "Iteration 85/100: Training Loss = 5688.631794037961\n",
      "Validation Loss = 5688.631794037961\n",
      "Iteration 86/100: Training Loss = 5685.753099377294\n",
      "Validation Loss = 5685.753099377294\n",
      "Iteration 87/100: Training Loss = 5682.884928872827\n",
      "Validation Loss = 5682.884928872827\n",
      "Iteration 88/100: Training Loss = 5679.967106693524\n",
      "Validation Loss = 5679.967106693524\n",
      "Iteration 89/100: Training Loss = 5677.090488569596\n",
      "Validation Loss = 5677.090488569596\n",
      "Iteration 90/100: Training Loss = 5674.200903709799\n",
      "Validation Loss = 5674.200903709799\n",
      "Iteration 91/100: Training Loss = 5671.293884470597\n",
      "Validation Loss = 5671.293884470597\n",
      "Iteration 92/100: Training Loss = 5668.456105418414\n",
      "Validation Loss = 5668.456105418414\n",
      "Iteration 93/100: Training Loss = 5665.607206118748\n",
      "Validation Loss = 5665.607206118748\n",
      "Iteration 94/100: Training Loss = 5662.755825170627\n",
      "Validation Loss = 5662.755825170627\n",
      "Iteration 95/100: Training Loss = 5659.926840082538\n",
      "Validation Loss = 5659.926840082538\n",
      "Iteration 96/100: Training Loss = 5657.0595197362445\n",
      "Validation Loss = 5657.0595197362445\n",
      "Iteration 97/100: Training Loss = 5654.206708656811\n",
      "Validation Loss = 5654.206708656811\n",
      "Iteration 98/100: Training Loss = 5651.382764425457\n",
      "Validation Loss = 5651.382764425457\n",
      "Iteration 99/100: Training Loss = 5648.5487967230265\n",
      "Validation Loss = 5648.5487967230265\n",
      "Iteration 100/100: Training Loss = 5645.764629014829\n",
      "Validation Loss = 5645.764629014829\n",
      "Training finished after 100 iterations\n",
      "Mean squared error: 5156.47\n",
      "Coefficient of determination: -0.07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from linear_regression import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "diabetes_X = diabetes_X.T\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train, diabetes_X_test = diabetes_X[:,:-20], diabetes_X[:,-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train, diabetes_y_test = diabetes_y[:-20], diabetes_y[-20:]\n",
    "\n",
    "regr = LinearRegression(alpha=0.01, max_iter=10000, early_stopping=True, n_iter_no_change=10, batch_size=100)\n",
    "\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, y_pred))\n",
    "    \n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
